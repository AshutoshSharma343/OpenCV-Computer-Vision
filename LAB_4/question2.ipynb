{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 53\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Instantiate the KerasTuner RandomSearch tuner\u001b[39;00m\n\u001b[0;32m     45\u001b[0m tuner \u001b[38;5;241m=\u001b[39m RandomSearch(\n\u001b[0;32m     46\u001b[0m     build_model,\n\u001b[0;32m     47\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist_tuning\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     51\u001b[0m )\n\u001b[1;32m---> 53\u001b[0m hp_batch_size \u001b[38;5;241m=\u001b[39m \u001b[43mhp\u001b[49m\u001b[38;5;241m.\u001b[39mChoice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m, values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m])\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Search for the best hyperparameters\u001b[39;00m\n\u001b[0;32m     55\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test), batch_size\u001b[38;5;241m=\u001b[39mhp_batch_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hp' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to between 0 and 1\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Function to create a model for hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "\n",
    "     # Add the first hidden layer with neurons varying between 250 to 260 with a step value of 2\n",
    "    hp_neurons = hp.Int('neurons', min_value=250, max_value=260, step=2)\n",
    "    model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "    model.add(layers.Dense(units=hp_neurons, activation='sigmoid'))\n",
    "\n",
    "    # Add the second hidden layer with 16 neurons and activation function tanh\n",
    "    model.add(Dense(16, activation='tanh'))\n",
    "\n",
    "    # Add the third hidden layer with 8 neurons and activation function relu\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "\n",
    "    # Add the fourth hidden layer with 4 neurons and activation function selu\n",
    "    model.add(Dense(4, activation='selu'))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Hyperparameters to tune\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01, 0.15])\n",
    "    # Compile model\n",
    "    model.compile(optimizer=SGD(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the KerasTuner RandomSearch tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Number of hyperparameter combinations to try\n",
    "    directory='tuner_logs',\n",
    "    project_name='mnist_tuning'\n",
    ")\n",
    "\n",
    "hp_batch_size = hp.Choice('batch_size', values=[4, 8, 16])\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test), batch_size=hp_batch_size)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hps)\n",
    "\n",
    "# Build the model with the best hyperparameters\n",
    "best_model = tuner.oracle.get_best_trials(num_trials=1)[0].hypermodel.build(best_hps)\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_model.fit(x_train, y_train, epochs=10, batch_size=best_hps['batch_size'], validation_split=0.1)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get the best hyperparameters\n",
    "# best_hps = tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values\n",
    "# print(\"Best Hyperparameters:\")\n",
    "# print(best_hps)\n",
    "\n",
    "# # Build the model with the best hyperparameters\n",
    "# best_model = tuner.oracle.get_best_trials(num_trials=1)[0].hypermodel.build(best_hps)\n",
    "\n",
    "# # Train the best model on the entire training set\n",
    "# best_model.fit(x_train, y_train, epochs=10, batch_size=best_hps['batch_size'], validation_split=0.1)\n",
    "\n",
    "# # Evaluate the best model on the test set\n",
    "# test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
    "# print(f\"\\nTest Accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyternotebook",
   "language": "python",
   "name": "jupyternotebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
