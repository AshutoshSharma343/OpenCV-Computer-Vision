{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import mnist \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you observe the input shape its 2 dimensional vector\n",
    "# for each image we have a (28*28) vector\n",
    "# we will convert the (28*28) vector into single dimensional vector of 1 * 784 \n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]) \n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d)\"%(X_train.shape[1]))\n",
    "print(\"Number of test examples :\", X_test.shape[0], \"and each image is of shape (%d)\"%(X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we observe the above matrix each cell is having a value between 0-255\n",
    "# before we move to apply machine learning algorithms lets try to normalize the data\n",
    "# X => (X - Xmin)/(Xmax-Xmin) = X/255\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Activation ,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 10\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "batch_size = 32\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.optimizers import Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer, learning_rate):\n",
    "     model = Sequential()\n",
    "     model.add(Dense(128, activation='sigmoid', input_shape=(input_dim,)))\n",
    "     model.add(Dropout(0.5))\n",
    "     model.add(Dense(64, activation='tanh'))\n",
    "     model.add(Dropout(0.4))\n",
    "     model.add(Dense(32, activation='relu'))\n",
    "     model.add(Dropout(0.3))\n",
    "     model.add(Dense(16, activation='selu'))\n",
    "     model.add(Dropout(0.1))\n",
    "     \n",
    "     #Output layer\n",
    "     model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile model with specified optimizer and learning rate\n",
    "     if optimizer == 'SGD':\n",
    "        model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "     elif optimizer == 'Adam':\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "     elif optimizer == 'AdamW':\n",
    "        optimizer = AdamW(learning_rate=learning_rate)\n",
    "        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "     elif optimizer == 'Nadam':\n",
    "        optimizer = Nadam(learning_rate=learning_rate)\n",
    "        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "     return model\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, batch_size):\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=batch_size, verbose=1,validation_data=(X_test, y_test))\n",
    "    test_accuracy = model.evaluate(X_test, y_test)\n",
    "    return test_accuracy\n",
    "\n",
    "num_models = 5\n",
    "batch_size = 32\n",
    "test_accuracies = []\n",
    "\n",
    "# Model-1: SGD\n",
    "print(\"Model-1: SGD\")\n",
    "for i in range(num_models):\n",
    "    model = create_model('SGD', None)\n",
    "    test_accuracy = train_and_evaluate_model(model, X_train, y_train, X_test, y_test, batch_size)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print(f\"Model-{i+1} Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Model-2: Adam\n",
    "print(\"\\nModel-2: Adam\")\n",
    "for i in range(num_models):\n",
    "    model = create_model('Adam', None)\n",
    "    test_accuracy = train_and_evaluate_model(model, X_train, y_train, X_test, y_test, batch_size)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print(f\"Model-{i+1} Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Model-3: AdamW\n",
    "print(\"\\nModel-3: AdamW\")\n",
    "for i in range(num_models):\n",
    "    model = create_model('AdamW', learning_rate=0.1)\n",
    "    test_accuracy = train_and_evaluate_model(model, X_train, y_train, X_test, y_test, batch_size)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print(f\"Model-{i+1} Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Model-4: Nadam\n",
    "print(\"\\nModel-4: Nadam\")\n",
    "for i in range(num_models):\n",
    "    model = create_model('Nadam', learning_rate=0.1)\n",
    "    test_accuracy = train_and_evaluate_model(model, X_train, y_train, X_test, y_test, batch_size)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print(f\"Model-{i+1} Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Compute and print the mean test accuracy\n",
    "mean_test_accuracy = sum(test_accuracies) / (num_models * 4)\n",
    "print(f\"\\nMean Test Accuracy: {mean_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, batch_size=32, epochs=5,verbose=1,validation_data=(X_test, y_test))\n",
    "# score = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyternotebook",
   "language": "python",
   "name": "jupyternotebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
