{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset and preprocess\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from keras import models\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "\n",
    "# One-hot encode labels\n",
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "test_labels = to_categorical(test_labels, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "469/469 [==============================] - 8s 15ms/step - loss: 0.0808 - accuracy: 0.2569\n",
      "Epoch 2/4\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.0723 - accuracy: 0.3440\n",
      "Epoch 3/4\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.0697 - accuracy: 0.3735\n",
      "Epoch 4/4\n",
      "469/469 [==============================] - 8s 16ms/step - loss: 0.0681 - accuracy: 0.3944\n",
      "1875/1875 [==============================] - 8s 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "Model-1 test accuracy: 0.3772\n",
      "Mean Test Accuracy across Models: 0.3772\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to create and train the specified CNN model\n",
    "def create_and_train_model(model_number):\n",
    "    model = models.Sequential(name=f'Model-{model_number}')\n",
    "\n",
    "    # Model architecture\n",
    "    model.add(Conv2D(32, (3, 3), strides=(2, 2), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(1, 1)))\n",
    "    model.add(Conv2D(16, (4, 4), strides=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D((4, 4), strides=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.01), \n",
    "#                   loss='categorical_crossentropy', \n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "#     # Reshape images to (28, 28, 1) for Conv2D layer\n",
    "#     train_images_reshaped = train_images.reshape((-1, 28, 28, 1))\n",
    "#     test_images_reshaped = test_images.reshape((-1, 28, 28, 1))\n",
    "\n",
    "#     # Train the model\n",
    "#     history = model.fit(train_images_reshaped, train_labels, \n",
    "#                         epochs=5, batch_size=128, \n",
    "#                         validation_split=0.2, verbose=1)\n",
    "    \n",
    "#     # Evaluate the model on the test set\n",
    "#     test_loss, test_accuracy = model.evaluate(test_images_reshaped, test_labels, verbose=2)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_accuracy(train_feature_16,y_train,test_feature_16,y_test):\n",
    "    rf=RandomForestClassifier()\n",
    "    rf=rf.fit(train_feature_16,y_train)\n",
    "    #train_pred=rf.predict(train_feature_16)\n",
    "    test_pred=rf.predict(test_feature_16)\n",
    "\n",
    "    return accuracy_score(test_pred,y_test)\n",
    "\n",
    "num_models = 1\n",
    "test_accuracies = []\n",
    "\n",
    "for i in range(num_models):\n",
    "     model_FE = create_and_train_model(i+1)\n",
    "     model_FE.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss='mse', metrics=['accuracy'])\n",
    "     # Train the model\n",
    "     model_FE.fit(train_images, train_labels, batch_size=128, epochs=4, verbose=1)\n",
    "     features_model = models.Model(inputs=model_FE.input, outputs=model_FE.layers[-2].output)\n",
    "     \n",
    "     train_features = features_model.predict(train_images)   \n",
    "     test_features = features_model.predict(test_images)\n",
    "     acurracy = get_accuracy(train_features, train_labels, test_features, test_labels)\n",
    "     test_accuracies.append(acurracy)\n",
    "     print(f'Model-{i+1} test accuracy: {acurracy:.4f}')\n",
    "\n",
    "# Compute the mean test accuracy\n",
    "mean_test_accuracy = np.mean(test_accuracies)\n",
    "print(f'Mean Test Accuracy across Models: {mean_test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "469/469 [==============================] - 7s 13ms/step - loss: 0.0408 - accuracy: 0.6852\n",
      "Epoch 2/4\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0181 - accuracy: 0.8795\n",
      "Epoch 3/4\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0145 - accuracy: 0.9040\n",
      "Epoch 4/4\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0128 - accuracy: 0.9148\n",
      "1875/1875 [==============================] - 5s 3ms/step\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Model-1 test accuracy: 0.9123\n",
      "Mean Test Accuracy across Models: 0.9123\n"
     ]
    }
   ],
   "source": [
    "# Function to create and train the specified CNN model\n",
    "def create_and_train_model(model_number):\n",
    "    model = models.Sequential(name=f'Model-{model_number}')\n",
    "\n",
    "    # Model architecture\n",
    "    model.add(Conv2D(32, (3, 3), strides=(2, 2), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(AveragePooling2D((2, 2), strides=(1, 1)))\n",
    "    model.add(Conv2D(16, (4, 4), strides=(2, 2), activation='relu'))\n",
    "    model.add(AveragePooling2D((4, 4), strides=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_accuracy(train_feature_16,y_train,test_feature_16,y_test):\n",
    "    rf=RandomForestClassifier()\n",
    "    rf=rf.fit(train_feature_16,y_train)\n",
    "    #train_pred=rf.predict(train_feature_16)\n",
    "    test_pred=rf.predict(test_feature_16)\n",
    "\n",
    "    return accuracy_score(test_pred,y_test)\n",
    "\n",
    "num_models = 1\n",
    "test_accuracies = []\n",
    "\n",
    "for i in range(num_models):\n",
    "     model_FE = create_and_train_model(i+1)\n",
    "     model_FE.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss='mse', metrics=['accuracy'])\n",
    "     # Train the model\n",
    "     model_FE.fit(train_images, train_labels, batch_size=128, epochs=4, verbose=1)\n",
    "     features_model = models.Model(inputs=model_FE.input, outputs=model_FE.layers[-2].output)\n",
    "     train_features = features_model.predict(train_images)   \n",
    "     test_features = features_model.predict(test_images)\n",
    "     acurracy = get_accuracy(train_features, train_labels, test_features, test_labels)\n",
    "     test_accuracies.append(acurracy)\n",
    "     print(f'Model-{i+1} test accuracy: {acurracy:.4f}')\n",
    "\n",
    "# Compute the mean test accuracy\n",
    "mean_test_accuracy = np.mean(test_accuracies)\n",
    "print(f'Mean Test Accuracy across Models: {mean_test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 9s 17ms/step - loss: 0.0726 - accuracy: 0.3569\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 8s 16ms/step - loss: 0.0422 - accuracy: 0.6966\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0260 - accuracy: 0.8259\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 8s 16ms/step - loss: 0.0210 - accuracy: 0.8610\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.0190 - accuracy: 0.8750\n",
      "1875/1875 [==============================] - 7s 4ms/step\n",
      "313/313 [==============================] - 2s 5ms/step\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 8s 14ms/step - loss: 0.0516 - accuracy: 0.5795\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0224 - accuracy: 0.8490\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0172 - accuracy: 0.8860\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0147 - accuracy: 0.9028\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0132 - accuracy: 0.9119\n",
      "1875/1875 [==============================] - 7s 4ms/step\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Random Forest Classifier Accuracy (Model-3): 0.915\n"
     ]
    }
   ],
   "source": [
    "model1 = models.Sequential()\n",
    "\n",
    "# Model architecture\n",
    "model1.add(Conv2D(32, (3, 3), strides=(2, 2), activation='relu', input_shape=(28, 28, 1)))\n",
    "model1.add(MaxPooling2D((2, 2), strides=(1, 1)))\n",
    "model1.add(Conv2D(16, (4, 4), strides=(2, 2), activation='relu'))\n",
    "model1.add(MaxPooling2D((4, 4), strides=(2, 2)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(8, activation='relu'))\n",
    "model1.add(Dense(10, activation='softmax'))\n",
    "model1.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss='mse', metrics=['accuracy'])\n",
    "\n",
    "model1.fit(train_images, train_labels, batch_size=128, epochs=5, verbose=1)\n",
    "features_model1 = models.Model(inputs=model_FE.input, outputs=model_FE.layers[-2].output)\n",
    "train_features1 = features_model.predict(train_images)   \n",
    "test_features1 = features_model.predict(test_images)\n",
    "\n",
    "\n",
    "model2 = models.Sequential()\n",
    "#Model architecture\n",
    "model2.add(Conv2D(32, (3, 3), strides=(2, 2), activation='relu', input_shape=(28, 28, 1)))\n",
    "model2.add(AveragePooling2D((2, 2), strides=(1, 1)))\n",
    "model2.add(Conv2D(16, (4, 4), strides=(2, 2), activation='relu'))\n",
    "model2.add(AveragePooling2D((4, 4), strides=(2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(8, activation='relu'))\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss='mse', metrics=['accuracy'])\n",
    "model2.fit(train_images, train_labels, batch_size=128, epochs=5, verbose=1)\n",
    "features_model2 = models.Model(inputs=model_FE.input, outputs=model_FE.layers[-2].output)\n",
    "train_features2 = features_model.predict(train_images)\n",
    "test_features2 = features_model.predict(test_images)\n",
    "\n",
    "# Stack the features horizontally from Model-1 and Model-2\n",
    "stacked_features = np.hstack((train_features1, train_features2))\n",
    "stacked_test_features = np.hstack((test_features1, test_features2))\n",
    "\n",
    "# Train a Random Forest classifier on the stacked features\n",
    "random_forest_stacked = RandomForestClassifier()\n",
    "random_forest_stacked.fit(stacked_features, train_labels)\n",
    "predictions_stacked = random_forest_stacked.predict(stacked_test_features)\n",
    "\n",
    "# Evaluate the Random Forest classifier\n",
    "accuracy_stacked = accuracy_score(test_labels, predictions_stacked)\n",
    "print(\"Random Forest Classifier Accuracy (Model-3):\", accuracy_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-4:  Extract  the  deep  features  from  Model-1  and  Model-2  stack  the features horizontally, reduce the dimension to either 8, 10 or 12 using principal  component  analysis  (PCA)  and  model  the  reduced  features  using  a Random Forest classifier. Identify the best number of reduced components  of PCA.\n",
    "\n",
    "# Perform PCA with different number of components\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# best_accuracy = 0\n",
    "# best_num_components = 0\n",
    "# for num_components in [8, 10, 12]:\n",
    "#     # Fit PCA\n",
    "#     pca = PCA(n_components=num_components)\n",
    "#     pca.fit(stacked_features)\n",
    "    \n",
    "#     # Transform the features\n",
    "#     reduced_features = pca.transform(stacked_features)\n",
    "#     reduced_test_features = pca.transform(stacked_test_features)\n",
    "    \n",
    "#     # Train a Random Forest classifier on the reduced features\n",
    "#     random_forest_pca = RandomForestClassifier()\n",
    "#     random_forest_pca.fit(reduced_features, train_labels)\n",
    "#     predictions_pca = random_forest_pca.predict(reduced_test_features)\n",
    "    \n",
    "#     # Evaluate the Random Forest classifier\n",
    "#     accuracy_pca = accuracy_score(test_labels, predictions_pca)\n",
    "#     print(\"Random Forest Classifier Accuracy (PCA with {} components): {:.4f}\".format(num_components, accuracy_pca))\n",
    "    \n",
    "#     # Update the best number of components if necessary\n",
    "#     if accuracy_pca > best_accuracy:\n",
    "#         best_accuracy = accuracy_pca\n",
    "#         best_num_components = num_components\n",
    "\n",
    "# print(\"Best number of PCA components:\", best_num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'min_samples_split': [5, 10]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(stacked_features, train_labels)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best cross-validation accuracy:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE BEST MODEL WAS THE RANDOM FOREST CLASSIFIER WITH THE STACKED FEATURES FROM MODEL 1 AND MODEL 2\n",
    "# WITH THE BEST PARAMETERS FOUND FROM THE GRID SEARCH\n",
    "# {'min_samples_split': 5, 'n_estimators': 200}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyternotebook",
   "language": "python",
   "name": "jupyternotebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
